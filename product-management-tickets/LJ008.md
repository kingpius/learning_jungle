## ğŸŸï¸ Product Ticket: LJ-008 â€” Child Diagnostic Test UI (10â€“15 Minute Learning Flow)

---

### ğŸ“Œ Ticket ID

LJ-008

---

### ğŸ§‘â€ğŸ’¼ Ownership & Roles

* **Primary Owner (Full Stack Engineer):** Full Stack Engineer
* **Product Manager:** PM (scope control, acceptance)
* **Test Owner:** Test Engineer (functional & flow validation)
* **Design Owner:** Product Designer (light involvement only)

---

### ğŸ¯ Objective

Deliver a **minimal, usable child-facing diagnostic test flow** that allows a child to:

1. Start a Maths diagnostic test
2. Answer generated questions
3. Submit the test
4. See their **rank outcome** and **treasure chest unlock state**

This ticket focuses on **usability and completeness**, not visual polish.

---

### ğŸ§© In Scope (MVP ONLY)

* Child-facing diagnostic test screen
* Display AI-generated multiple-choice questions
* One question per screen (or simple list)
* Answer selection (Aâ€“D)
* Submit test action
* Results screen showing:

  * Score percentage
  * Bronze / Silver / Gold rank (if applicable)
  * Treasure Chest status (locked / unlocked)

---

### ğŸš« Out of Scope (Explicitly Excluded)

* Avatars, animations, or gamification visuals
* Timers, streaks, or XP
* Adaptive difficulty during the test
* Retakes or multiple attempts
* Parent dashboards
* Styling beyond basic readability

---

### ğŸ§  Functional Requirements

#### 1. Test Start

* Child can initiate a diagnostic test for Maths
* System loads pre-generated questions (from LJ-006)
* Completed tests cannot be restarted

---

#### 2. Question Interaction

* Questions displayed with four answer options (Aâ€“D)
* Child can select exactly one option per question
* All questions must be answered before submission

---

#### 3. Test Submission

* On submit:

  * Answers are evaluated
  * Score percentage calculated
  * Diagnostic Test marked as completed
  * Ranking logic executed (LJ-007)
  * Treasure Chest unlock evaluated (LJ-003)

---

#### 4. Results View

* Display final score percentage
* Display assigned rank (or no rank)
* Display Treasure Chest status

---

### ğŸ§ª Acceptance Criteria

| Scenario                 | Expected Result     |
| ------------------------ | ------------------- |
| Child starts test        | Questions load      |
| Child selects answers    | Selections saved    |
| Child submits test       | Completion recorded |
| Score calculated         | Percentage correct  |
| Rank displayed           | Correct rank shown  |
| Treasure Chest unlocked  | Status reflected    |
| Completed test revisited | Read-only view      |

All criteria must pass for acceptance.

---

### ğŸ” Non-Functional Requirements

* Must reuse existing models and logic (LJ-003 â†’ LJ-007)
* Must respect parent/child access control
* Must not bypass completion or ranking services
* Must remain usable on desktop and tablet

---

### ğŸ—ï¸ Technical Notes

* Server-rendered templates or simple frontend framework acceptable
* No client-side business logic duplication
* Use existing services for scoring, ranking, and unlocking
* Keep UI code thin and replaceable

---

### ğŸ§­ Dependencies

* LJ-003 â€” Treasure Chest Core Logic âœ…
* LJ-004 â€” Child Profile Model & CRUD âœ…
* LJ-005 â€” Diagnostic Test Model & Completion Event âœ…
* LJ-006 â€” AI Diagnostic Question Generation (Maths Only) âœ…
* LJ-007 â€” Ranking Logic (Bronze / Silver / Gold) âœ…

---

### ğŸ Definition of Done

* Feature branch created: `feature/LJ-008-diagnostic-ui`
* Child can complete full diagnostic flow end-to-end
* Results correctly reflect backend logic
* All acceptance criteria met
* Pull Request opened, reviewed, and merged
* No scope creep introduced

---

### ğŸš¦ Priority

P0 â€” MVP usability completion

---

### ğŸ”„ Updates & Coordination Log

**Update 2025-12-18 â€” PM**
- Weâ€™re building on LJ-006/007 foundations. The UI must orchestrate existing backend services (question retrieval, answer submission, ranking, treasure unlock). No new business logic client-side.
- **Full Stack Engineer:** propose lightweight Django templates or simple frontend to render child flow. Implement endpoints/views for: start test, render questions, capture answers, submit test, show results. Ensure every action enforces parent/child ownership and uses existing services for scoring/ranking/unlock. Provide plan (screens/routes, controller/service breakdown) before coding.
- **Test Engineer:** prepare functional flow tests (start â†’ answer selection â†’ submit â†’ results) plus edge cases (incomplete answers, completed test revisit read-only). Ensure they run headless via Django test client; no manual QA dependencies.
- **Design Owner:** before engineers build, produce low-fidelity HTML mockups using a lightweight design system (simple typography, spacing, button styles) so states (question, answer selection, results) are clear. Keep it rough but semantic; no CSS frameworks beyond basic utility classes. This gives engineers a concrete reference without over-investing in polish.
- Next checkpoint: share UI/service design (screens + route map) in this ticket prior to implementation.

**Update 2025-12-18 â€” Full Stack Engineer**
- Proposed flow (all server-rendered Django templates under new `diagnostics` app section):
  1. **Test Overview (`GET /diagnostics/<child_id>/start/`)** â€“ parent logs in, selects child, view shows latest pending Maths diagnostic (or CTA to create). POST to same route creates `DiagnosticTest` via existing service (reusing LJ-006 question generation) and redirects to question flow.
  2. **Question Flow (`GET/POST /diagnostics/tests/<uuid:test_id>/questions/`)** â€“ displays questions one-per-page (with simple pagination) or stacked list; stores child selections in a new `DiagnosticResponse` model keyed to (`test`, `question`). View enforces parent ownership via `child__parent=request.user`. POST validates that each question has exactly one answer before allowing â€œSubmit Testâ€.
  3. **Submission (`POST /diagnostics/tests/<uuid:test_id>/submit/`)** â€“ service computes `correct_answers` by comparing `DiagnosticResponse.selected_option` to `DiagnosticQuestion.correct_option`, updates `DiagnosticTest.correct_answers`, and calls existing `DiagnosticTest.complete()` so ranking + treasure chest unlock fire. Endpoint rejects re-submission if `is_completed=True`.
  4. **Results (`GET /diagnostics/tests/<uuid:test_id>/results/`)** â€“ read-only summary showing score %, rank (or â€œNo rank yetâ€), and treasure chest state (read from `TreasureChest` for that child). If a completed test is revisited, question view redirects here.
- **Data additions**: introduce `DiagnosticResponse` model with fields (`test`, `question`, `selected_option`, timestamps) to persist answers for scoring + read-only review. Views/services reuse existing `assessments.diagnostics.services` helpers for generation and `DiagnosticTest.complete()` for rank/unlock.
- **Templates**: `diagnostics/start.html`, `diagnostics/questions.html`, `diagnostics/results.html` with basic semantic HTML (headings, list of options, submit buttons). Minimal CSS inline to ensure readability.
- **Access control**: all routes guarded by `login_required`; querysets filter on `child__parent=request.user`. Completed tests render questions view in read-only mode (radio inputs disabled + message) and route submission attempts to results.
- **Next steps**: once PM approves this route/service plan, Iâ€™ll scaffold the `diagnostics` app views, `DiagnosticResponse` model + migration, templates, and accompanying functional tests covering the full flow + edge cases (missing answers, revisits, unauthorized parent).

**Update 2025-12-18 â€” Test Engineer**
- Reviewed repo for LJ-008 artifacts: there are currently no `diagnostics/` templates, views, urls, or `DiagnosticResponse` model (confirmed via `rg --files -g "*.html"` and absence of app directories). Feature remains unimplemented, so end-to-end UI testing cannot start.
- Prepared automated test plan (Django `TestCase` + client + fixtures) covering:
  1. Start flow renders pending Maths diagnostic for parent-owned child; POST creates test + redirects to question list.
  2. Question view enforces single selection per MCQ, blocks submission with validation errors when answers missing, and persists selections in `DiagnosticResponse`.
  3. Submit endpoint scores responses, updates `correct_answers`, triggers `DiagnosticTest.complete()` and verifies Bronze/Silver/Gold mapping + Treasure Chest unlock propagation.
  4. Results view displays score %, rank (or â€œNo rankâ€), and treasure status; revisiting completed test shows read-only state and disables submission.
  5. Access control scenarios (parent cannot access other childâ€™s test, unauthenticated redirect to login).
  6. Regression guards: repeated submissions rejected with clear messaging; GET questions on completed test redirects to results.
- Test data prerequisites: leverage existing `Child`, `DiagnosticTest`, `DiagnosticQuestion`, and `TreasureChest` factories; seed deterministic AI questions via mocks from LJ-006 helpers. Suites will live under `assessments/tests.py` (or new `diagnostics/tests.py`) and run via `python manage.py test assessments diagnostics rewards`.
- Blocker: awaiting backend/UI implementation + migrations. Will execute and document test evidence once routes/templates land and migrations are available.

**Update 2025-12-18 â€” PM**
- Acknowledged Full Stack + Test plans. Green-light to proceed: Full Stack may begin implementation per proposed route/service design; Test Engineer to prepare fixtures/mocks in parallel so test coverage lands with the feature.
- Reminder: coordinate early with Design Owner to review the low-fidelity HTML mockups before finalizing templates so the child flow stays consistent.
